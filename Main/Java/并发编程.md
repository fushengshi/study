# 并发编程

## 线程

进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。

- 线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。

- 与进程不同的是同类的多个线程共享进程的**堆**和**方法区**资源，每个线程有自己的**程序计数器**、**虚拟机栈**和**本地方法栈**。

堆和方法区是所有线程共享的资源，其中堆是进程中最大的一块内存，主要用于存放新创建的对象（几乎所有对象都在这里分配内存），方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。

<img src="https://gitee.com/fushengshi/image/raw/master/image-20240510002759034.png" alt="image-20240510002759034" style="zoom:67%;" />

> **Java 线程的本质其实就是操作系统的线程**，操作系统内核进行线程的调度和管理。
>
> 在 Windows 和 Linux 等主流操作系统中，Java 线程采用的是一对一（一个用户线程对应一个内核线程）的线程模型，也就是一个 Java 线程对应一个系统内核线程。
>
> 是否共享地址空间几乎是进程和线程之间的本质区别。Linux 内核并不区别对待它们，线程对于内核来说仅仅是一个共享特定资源的进程而已。



### 线程创建

严格来说 Java 只有一种方式可以创建线程，就是通过 `new Thread().start()` 创建。不管是哪种方式最终依赖于 `new Thread().start()`。

所谓的 Runnable、Callable 对象，这仅仅只是线程体，也就是提供给线程执行的任务，并不属于真正的 Java 线程，它们的执行最终需要依赖于 `new Thread()`。



### 线程上下文切换

线程在执行过程中会有自己的运行条件和状态（也称上下文），比如上文所说到过的程序计数器，栈信息等。当出现如下情况的时候，线程会从占用 CPU 状态中退出。

- 主动让出 CPU，比如调用了 `sleep()/wait()` 等。

  `sleep()` 方法没有释放锁，而 `wait()` 方法释放了锁 。

- 时间片用完，因为操作系统要防止一个线程或者进程长时间占用 CPU 导致其他线程或者进程饿死。

- 调用了阻塞类型的系统中断，比如请求 I/O，线程被阻塞。

- 被终止或结束运行。



## JMM

JMM（Java 内存模型）主要定义了对于一个共享变量，当另一个线程对这个共享变量执行写操作后，这个线程对这个共享变量的可见性。

编程语言也可以直接复用操作系统层面的内存模型。不同的操作系统内存模型不同。直接复用操作系统层面的内存模型可能会导致同样一套代码换了一个操作系统无法执行。Java 语言是跨平台的，它需要自己提供一套内存模型以屏蔽系统差异。

JMM 抽象了线程和主内存之间的关系，就比如说线程之间的共享变量必须存储在主内存中。

Java 的内存模型实现总是从**主存**（即共享内存）读取变量。在 Java 内存模型下，线程可以把变量保存**本地内存** （比如机器的寄存器）中，不是直接在主存中进行读写。可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成数据的不一致。

<img src="https://gitee.com/fushengshi/image/raw/master/image-20240510020329555.png" alt="image-20240510020329555" style="zoom: 67%;" />

- 主内存

  所有线程创建的实例对象都存放在主内存中，不管该实例对象是成员变量，还是局部变量，类信息、常量、静态变量都是放在主内存中。

  为了获取更好的运行速度，虚拟机及硬件系统可能会让工作内存优先存储于寄存器和高速缓存中。

- 本地内存

  每个线程都有一个私有的本地内存，本地内存存储了该线程以读 / 写共享变量的副本。每个线程只能操作自己本地内存中的变量，无法直接访问其他线程的本地内存。如果线程间需要通信，必须通过主内存来进行。

  本地内存是 JMM 抽象出来的一个概念，**并不真实存在**，它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。

  > 注意区别于 JVM 的本地内存。

> Java 内存区域和内存模型是完全不一样的两个东西：
>
> - JVM 内存结构和 Java 虚拟机的运行时区域相关，定义了 JVM 在运行时如何分区存储程序数据，比如说堆主要用于存放对象实例。
>
> - JMM 和 Java 的并发编程相关，抽象了线程和主内存之间的关系就比如说线程之间的共享变量必须存储在主内存中，规定了从 Java 源代码到 CPU 可执行指令的这个转化过程要遵守哪些和并发相关的原则和规范，其主要目的是为了简化多线程编程，增强程序可移植性的。

### happens-before 原则

happens-before 原则表达的意义其实并不是一个操作发生在另外一个操作的前面，更准确地来说，它更想表达的意义是前一个操作的结果对于后一个操作是可见的，无论这两个操作是否在同一个线程里。

- 程序顺序规则

  一个线程内，按照代码顺序，书写在前面的操作 happens-before 于书写在后面的操作。

- 解锁规则

  解锁 happens-before 于加锁。

- volatile 变量规则

  对一个 volatile 变量的写操作 happens-before 于后面对这个 volatile 变量的读操作。

  就是对 volatile 变量的写操作的结果对于发生于其后的任何操作都是可见的。

- 传递规则

  如果 A happens-before B，且 B happens-before C，那么 A happens-before C。

- 线程启动规则

  Thread 对象的 `start()` 方法 happens-before 于此线程的每一个动作。



### 指令重排

为了提升性能，计算机在执行程序代码的时候，会对指令进行重排序。

- 编译器优化重排

  编译器（包括 JVM、JIT 编译器等）在不改变单线程程序语义的前提下，重新安排语句的执行顺序。

- 指令并行重排

  现代处理器采用了指令级并行技术（Instruction-Level Parallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。

Java 源代码经历 编译器优化重排 -> 指令并行重排 -> 内存系统重排 的过程，最终变成操作系统可执行的指令序列。指令重排序可以保证串行语义一致，但是没有义务保证多线程间的语义也一致 ，所以在多线程下，指令重排序可能会导致一些问题。

编译器和处理器的指令重排序的处理方式不一样。

- 对于编译器，通过禁止特定类型的编译器重排序的方式来禁止重排序。
- 对于处理器，通过插入内存屏障（Memory Barrier，内存栅栏 Memory Fence）的方式来禁止特定类型的处理器重排序。指令并行重排和内存系统重排都属于是处理器级别的指令重排序。



## synchronized

在 Java 6 之后， synchronized 引入了大量的优化如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销，这些优化让 synchronized 锁的效率提升了很多。synchronized 还是可以在实际项目中使用的，像 JDK 源码、很多开源框架都大量使用了 synchronized 。

- 普通同步方法，锁是当前实例对象（this）

  一个对象多个普通同步方法，用同一个锁，不同对象用不同锁。

- 静态同步方法（static synchronized）

  锁是当前Class对象，所有对象同一个锁。

- 同步方法块

  锁是synchronized括号配置的对象。

synchronized 同步语句块的实现使用的是 `monitorenter` 和 `monitorexit` 指令，其中 `monitorenter` 指令指向同步代码块的开始位置，`monitorexit` 指令则指明同步代码块的结束位置。

当执行 `monitorenter` 指令时，线程试图获取锁也就是获取 **对象监视器 monitor** 的持有权。

> 在 Java 虚拟机（HotSpot）中，Monitor 是基于 C++ 实现的，由 ObjectMonitor 实现的。每个对象中都内置了一个 ObjectMonitor 对象。
>
> `wait()/notify()` 等方法也依赖于 monitor 对象，因此只有在同步的块或者方法中才能调用 `wait()/notify()` 等方法，否则会抛出 java.lang.IllegalMonitorStateException 的异常的原因。

> 对象头见附录。

### 锁升级

- 无锁

  对于共享资源，不涉及多线程的竞争访问。

- 偏向锁

  共享资源首次被访问时，JVM 会对该共享资源对象做一些设置，比如将对象头中是否偏向锁标志位置为 1，对象头中的线程 ID 设置为当前线程 ID（操作系统的线程 ID）。

  线程再次访问这个共享资源时，会根据偏向锁标识和线程 ID 进行比对，相同则直接获取到锁，进入临界区域（锁保护，线程间只能串行访问的代码）。

- 轻量级锁

  当多个线程同时申请共享资源锁的访问时产生了竞争。

  JVM 会尝试使用轻量级锁，以 CAS 方式来获取锁（一般就是自旋加锁，不阻塞线程采用循环等待的方式），成功则获取到锁，自旋达到一定次数未成功，锁升级到重量级锁。

- 重量级锁

  重量级锁由操作系统来实现，性能消耗相对较高。

  - 如果共享资源锁已经被某个线程持有，此时是偏向锁状态，未释放锁前，再有其它线程竞争，则会升级到重量级锁。

  - 轻量级锁状态多线程竞争锁，自旋达到一定次数未成功，也会升级到重量级锁。



## volatile

Java volatile 关键字可以保证变量的可见性，变量声明为 volatile 指示 JVM 变量是共享且不稳定的，每次使用都到主存中进行读取。

- 可见性

  JVM 每次使用 volatile 变量都到主存中进行读取。

  > 可见性通过 Lock 指令，触发缓存一致性协议（MESI）保证的，通过总线嗅探机制把缓存数据的状态变化广播到所有的核。

- 有序性

  在对 volatile 变量进行读写操作的时候，会通过插入特定的**内存屏障**的方式来禁止指令重排序。

  - 在每个 volatile 写操作的前面插入一个 StoreStore 屏障。
  - 在每个 volatile 写操作的后面插入一个 StoreLoad 屏障。
  - 在每个 volatile 读操作的前面插入一个 LoadLoad 屏障。
  - 在每个 volatile 读操作的后面插入一个 LoadStore 屏障。

  > StoreStore 屏障：禁止 StoreStore 屏障的前后 Store 写操作重排。
  >
  > LoadLoad 屏障：禁止 LoadLoad 屏障的前后 Load 读操作进行重排。
  >
  > LoadStore 屏障：禁止 LoadStore 屏障的前面 Load 读操作跟 LoadStore 屏障后面的 Store 写操作重排。
  >
  > StoreLoad 屏障：禁止 LoadStore 屏障前面的 Store 写操作跟后面的 Load/Store 读写操作重排。




## ThreadPoolExecutor

线程池提供了一种限制和管理资源（包括执行一个任务）的方式。 每个线程池还维护一些基本统计信息，例如已完成任务的数量。

- 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。
- 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

### 参数

- corePoolSize

  任务队列未达到队列容量时，最大可以同时运行的线程数量。

- maximumPoolSize

  任务队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。

- workQueue

  新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。

- keepAliveTime

  线程池中的线程数量大于 `corePoolSize` 的时候，如果没有新的任务提交，核心线程外的线程不会立即销毁，而是等待的时间超过 `keepAliveTime` 才回收销毁。

- unit

  `keepAliveTime` 参数的时间单位。

- threadFactory

  executor 创建新线程的时候会用到。

- handler

  拒绝策略。

  - ThreadPoolExecutor.AbortPolicy

    抛出 RejectedExecutionException 来拒绝新任务的处理。

  - ThreadPoolExecutor.CallerRunsPolicy

    调用执行自己的线程运行任务，也就是直接在调用 `execute()` 方法的线程中运行被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。

    如果应用程序可以承受此延迟并且要求任何一个任务请求都要被执行可以选择这个策略。

  - ThreadPoolExecutor.DiscardPolicy

    不处理新任务，直接丢弃掉。

  - ThreadPoolExecutor.DiscardOldestPolicy

    此策略将丢弃最早的未处理的任务请求。

  > 使用 `execute()` 时，未捕获异常导致线程终止，线程池创建新线程替代。
  >
  > 使用 `submit()` 时，异常被封装在 Future 中，线程继续复用。

### 执行流程

- 如果当前运行的线程数小于核心线程数，那么就会新建一个线程来执行任务。

- 如果当前运行的线程数等于或大于核心线程数，但是小于最大线程数，把该任务放入到任务队列里等待执行。

- 如果向任务队列投放任务失败（任务队列已经满了），但是当前运行的线程数是小于最大线程数的，就**新建一个线程来执行任务**。

- 如果当前运行的线程数已经等同于最大线程数了，新建线程将会使当前运行的线程超出最大线程数，那么当前任务会被拒绝，拒绝策略会调用 `RejectedExecutionHandler.rejectedExecution()` 方法。



## ThreadLocal

ThreadLocal 类主要解决的就是让每个线程绑定自己的值。

每个 Thread 中都具备一个 ThreadLocalMap，而 ThreadLocalMap 可以存储以 ThreadLocal 为 key ，Object 对象为 value 的键值对。

```java
public class Thread implements Runnable {
  ThreadLocal.ThreadLocalMap threadLocals = null;
    ...
}

static class ThreadLocalMap {
  ThreadLocalMap(ThreadLocal<?> firstKey, Object firstValue) {
    table = new Entry[INITIAL_CAPACITY];
    int i = firstKey.threadLocalHashCode & (INITIAL_CAPACITY - 1);
    table[i] = new Entry(firstKey, firstValue);
    size = 1;
    setThreshold(INITIAL_CAPACITY);
  }

  static class Entry extends WeakReference<ThreadLocal<?>> {
    Object value;

    Entry(ThreadLocal<?> k, Object v) {
      super(k);
      value = v;
    }
  }
}
```

### 内存泄漏

```java
static class Entry extends WeakReference<ThreadLocal<?>> {
  Object value;

  Entry(ThreadLocal<?> k, Object v) {
    super(k); // 弱引用
    value = v;
  }
}
```

- ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用，而 value 是强引用。ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。

- ThreadLocalMap 中会出现 key 为 null 的 Entry。假如不做任何措施，value 永远无法被 GC 回收，这个时候就会产生内存泄露。

ThreadLocalMap 实现中已经考虑了这种情况，在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal 方法后最好手动调用 `remove()` 方法。



## CAS

CAS（Compare And Swap，比较与交换），用于实现乐观锁，被广泛应用于各大框架中。CAS 的思想很简单，就是用一个预期值和要更新的变量值进行比较，两值相等才会进行更新。

> CAS 是乐观锁，但是自旋锁基于 CAS 加了 while 或者睡眠 CPU 的操作而产生自旋的效果，加锁失败会忙等待直到拿到锁，自旋锁是要事先拿到锁才能修改数据的，所以是悲观锁。

Unsafe 提供的 CAS 方法（如 `compareAndSwapXXX()`）底层实现即为 CPU 指令 `cmpxchg` 。

### ABA 问题

如果一个变量 V 初次读取的时候是 A 值，并且在准备赋值的时候检查到它仍然是 A 值，在这段时间它的值可能被改为其他值，然后又改回 A，CAS 操作会误认为它从来没有被修改过。

ABA 问题的解决思路是在变量前面追加上**版本号或者时间戳**。JDK 1.5 以后的 AtomicStampedReference 类就是用来解决 ABA 问题的，其中的 `compareAndSet()` 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。



## 死锁

### 预防死锁

- 破坏请求与保持条件：

  一次性申请所有的资源。

- 破坏不剥夺条件：

  占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。

- 破坏循环等待条件：

  靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。

### 避免死锁

避免死锁就是在资源分配时，借助于算法（比如银行家算法）对资源分配进行计算评估，使其进入安全状态。



## AQS

AQS（AbstractQueuedSynchronizer，抽象队列同步器）。这个类在 java.util.concurrent.locks 包下面。

AQS 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是基于 CLH 锁 （Craig，Landin，and Hagersten locks）实现的。

![image-20240509000513352](https://gitee.com/fushengshi/image/raw/master/image-20240509000513352.png)

AQS 定义两种资源共享方式：

- Exclusive

  独占，只有一个线程能执行，如 ReentrantLock。

- Share

  共享，多个线程可同时执行，如 Semaphore / CountDownLatch。

AQS 使用 int 成员变量 `state` 表示同步状态，通过内置的 FIFO 线程等待/等待队列 来完成获取资源线程的排队工作。

```java
// 共享变量，使用volatile修饰保证线程可见性
private volatile int state;
```

AQS 使用了模板方法模式，自定义同步器时需要重写下面几个 AQS 提供的钩子方法：

```java
// 独占方式。尝试获取资源，成功则返回true，失败则返回false。
protected boolean tryAcquire(int)
// 独占方式。尝试释放资源，成功则返回true，失败则返回false。
protected boolean tryRelease(int)
// 共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
protected int tryAcquireShared(int)
// 共享方式。尝试释放资源，成功则返回true，失败则返回false。
protected boolean tryReleaseShared(int)
// 该线程是否正在独占资源。只有用到condition才需要去实现它。
protected boolean isHeldExclusively()
```

> 例如 FairSync、NonFairSync。



### CLH 锁

CLH 锁是对自旋锁的一种改进。

- 将线程组织成一个队列，保证先请求的线程先获得锁，避免了饥饿问题。
- 锁状态去中心化，让每个线程在不同的状态变量中自旋，这样当一个线程释放它的锁时，只能使其后续线程的高速缓存失效，缩小了影响范围，从而减少了 CPU 的开销。

所有请求获取锁的线程会排列在链表队列中，自旋访问队列中前一个节点的状态。当一个节点释放锁时，只有它的后一个节点才可以得到锁。

CLH 锁本身有一个队尾指针 Tail，它是一个原子变量，指向队列最末端的 CLH 节点。每一个 CLH 节点有两个属性：所代表的线程和标识是否持有锁的状态变量。

- 当一个线程要获取锁时，它会对 Tail 进行一个 `getAndSet()` 的原子操作。该操作会返回 Tail 当前指向的节点，也就是当前队尾节点，然后使 Tail 指向这个线程对应的 CLH 节点，成为新的队尾节点。
- 入队成功后，该线程会轮询上一个队尾节点的状态变量，当上一个节点释放锁后，它将得到这个锁。

两个缺点：

- 第一是因为有自旋操作，当锁持有时间长时会带来较大的 CPU 开销。
- 第二是基本的 CLH 锁功能单一，不改造不能支持复杂的功能。

### AQS 对 CLH 的改造

- AQS 将自旋操作改为阻塞线程操作。

- AQS 对 CLH 锁进行改造和扩展。

  AQS 每个节点的状态：

  ```java
  /*
      SIGNAL		表示该节点正常等待
      PROPAGATE	应将 releaseShared 传播到其他节点
      CONDITION	该节点位于条件队列，不能用于同步队列节点
      CANCELLED	由于超时、中断或其他原因，该节点被取消
  */
  volatile int waitStatus;
  ```

  AQS 中显式的维护前驱节点和后继节点，需要释放锁的节点会显式通知下一个节点解除阻塞。



### AQS 应用

#### ReentrantLock

AQS 使用了模板设计模式，父类中定义加锁流程，子类去实现具体的加锁逻辑。

```java
// 非公平锁
static final class NonfairSync extends Sync {
  // 加锁
  final void lock() {
    // 先尝试加锁（使用CAS设置state=1）
    if (compareAndSetState(0, 1))
      // 加锁成功，就把当前线程设置为持有锁线程
      setExclusiveOwnerThread(Thread.currentThread());
    else
      // 没加锁成功，再调用父类AQS中实际的加锁逻辑
      acquire(1);
  }
}
```

#### Semaphore

Semaphore 是共享锁的一种实现，它默认构造 AQS 的 `state` 值为 permits，可以将 permits 的值理解为许可证的数量，只有拿到许可证的线程才能执行。

以无参 `acquire()` 方法为例：

- 调用 `semaphore.acquire()` ，线程尝试获取许可证。

  - `state > 0` 表示可以获取成功。

    尝试使用 CAS 操作去修改 `state` 的值 `state = state - 1`。

  - `state <= 0` 表示许可证数量不足，获取失败。

    创建一个 Node 节点加入**等待队列**，挂起当前线程。

#### CountDownLatch

CountDownLatch 是共享锁的一种实现，它默认构造 AQS 的 `state` 值为 `count`。

当线程调用 `countDown()` 时，其实使用了 `tryReleaseShared()` 方法以 CAS 的操作来减少 `state`，直至 `state` 为 0 。当 `state` 为 0 时，表示所有的线程都调用了 `countDown()` 方法，在 CountDownLatch 上等待的线程就会被唤醒并继续执行。

以无参 `await()` 方法为例：

- 当调用 `await()` 的时候，如果 `state` 不为 0 证明任务还没有执行完毕，`await()` 就会一直阻塞， `await()` 之后的语句不会被执行
- main 线程被加入到**等待队列**也就是 CLH 队列中。
- CountDownLatch 会自旋 CAS 判断 `state == 0`，如果 `state == 0` 的话，就会释放所有等待的线程，`await()` 方法之后的语句得到执行。

#### CyclicBarrier

CycliBarrier 是基于 ReentrantLock（ReentrantLock 也属于 AQS 同步器）和 Condition 的。



# 附录

## 并发编程三个重要特性

### 原子性

一次操作或者多次操作，要么所有的操作全部都得到执行并且不会受到任何因素的干扰而中断，要么都不执行。

Java 可以借助 synchronized、各种 Lock 以及各种原子类实现原子性。

synchronized 和各种 Lock 可以保证任一时刻只有一个线程访问该代码块，因此可以保障原子性。各种原子类是利用 CAS 操作（可能也会用到 volatile 或者 final 关键字）来保证原子操作。

### 可见性

当一个线程对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。

- volatile ：

  JVM 每次使用 volatile 变量都到主存中进行读取。

- synchronized：

  synchronized 通过内存屏障保证可见性。

  `monitorenter` 指令其实还具有 Load 屏障的作用。也就是通过 `monitorenter` 指令之后，synchronized 内部的共享变量，每次读取数据的时候被强制**从主内存读取最新的数据**。

  同样的道理 `monitorexit` 指令也具有 Store 屏障的作用，也就是让 synchronized 代码块内的共享变量，如果数据有变更的，**强制刷新回主内存**。

- Lock：

  ```Java
  private volatile int state;
  
  void lock() {
      read state
      if (can get lock)
          write state
  }
  
  void unlock() {
      write state
  }
  ```

  借助了 volatile 关键字间接地实现了可见性。一个 volatile 变量的写操作发生在这个 volatile 变量随后的读操作之前。

  当线程 b 执行获取锁操作，读取了 `state` 变量的值后，线程 a 在写入 `state` 变量之前的任何操作结果对线程 b 都是可见的。

### 有序性

由于指令重排序问题，代码的执行顺序未必就是编写代码时候的顺序。

- volatile：

  对这个变量进行读写操作的时候，会通过插入特定的**内存屏障**的方式来禁止指令重排序。

- synchronized：

  synchronized通过**内存屏障来保证有序性**。

- Lock：



## Java 对象头

- Mark Word（标记字段）

  存储对象的 HashCode，分代年龄、锁标志位（锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳）等信息。

  64 位 JVM 的 Mark Word 组成如下：

  ![image-20240510013954568](https://gitee.com/fushengshi/image/raw/master/image-20240510013954568.png)

- Klass Point（类型指针）

  对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。



## AQS 源码

```java
// 加锁方法，传参是1
public final void acquire(int arg) {
    // 首先尝试获取锁，如果获取成功，则设置state+1，exclusiveOwnerThread=currentThread（留给子类实现）
    if (!tryAcquire(arg) &&
            // 如果没有获取成功，把线程组装成Node节点，追加到同步队列末尾
            acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) {
        // 加入同步队列后，将自己挂起
        selfInterrupt();
    }
}

// 追加到同步队列末尾后，再次尝试获取锁
final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (; ; ) {
            // 找到前驱节点
            final Node p = node.predecessor();
            // 如果前驱节点是头结点，就再次尝试获取锁
            if (p == head && tryAcquire(arg)) {
                // 获取锁成功后，把自己设置为头节点
                setHead(node);
                p.next = null;
                failed = false;
                return interrupted;
            }
            // 如果还是没有获取到锁，找到可以将自己唤醒的节点
            if (shouldParkAfterFailedAcquire(p, node) &&
                    // 将自己挂起
                    parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
```

### Condition

```java
public class ConditionObject implements Condition, java.io.Serializable {
    private transient Node firstWaiter;
    private transient Node lastWaiter;
    
    // 等待方法
    public final void await() throws InterruptedException {
        // 如果线程已中断，则中断
        if (Thread.interrupted())
            throw new InterruptedException();
        // 追加到条件队列末尾
        Node node = addConditionWaiter();
        // 释放锁
        int savedState = fullyRelease(node);
        int interruptMode = 0;
        // 有可能刚加入条件队列就被转移到同步队列了，如果还在条件队列挂起自己
        while (!isOnSyncQueue(node)) {
            LockSupport.park(this);
            if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
                break;
        }
        // 如果已经转移到同步队列，就尝试获取锁
        if (acquireQueued(node, savedState) && interruptMode != THROW_IE)
            interruptMode = REINTERRUPT;
        if (node.nextWaiter != null)
            // 清除条件队列中已取消的节点
            unlinkCancelledWaiters();
        if (interruptMode != 0)
            reportInterruptAfterWait(interruptMode);
    }

    // 唤醒条件队列的头节点
    public final void signal() {
        // 只有持有锁的线程才能调用signal方法
        if (!isHeldExclusively())
            throw new IllegalMonitorStateException();
        // 找到条件队列的头节点
        Node first = firstWaiter;
        if (first != null)
            // 开始唤醒
            doSignal(first);
    }
}
```

持有锁的线程可以调用 `await()` 方法，作用是释放锁，并追加到条件队列末尾。

`signal()` 唤醒条件队列的头节点，并追加到同步队列末尾。



## ThreadPoolExecutor 源码

线程池本质上对应生产者消费者模型：

- 生产者：调用 `execute()` 方法提交任务的线程。
- 消费者：线程池中的 Worker，不断循环获取阻塞队列中的任务。
- 中间层：阻塞队列，用于存放任务将生产者和消费者解耦，生产者（线程）只管生产，消费者（Worker 线程）只管消费。

### Worker

Worker 内部封装了一个线程，用来执行任务，而且 Worker 类实现了 AbstractQueuedSynchronizer，用来实现对临界资源的加解锁。

- Worker 执行任务时获得锁，执行完毕释放锁。

- Worker 具有不可重入特性，目的是为了防止 Worker 在线程池控制类操作时获得锁。

```java
public void execute(Runnable command) {
    if (command == null) {
        throw new NullPointerException();
    }
    int c = ctl.get();
    // 根据ctl值获取线程池内线程数，判断线程数是否小于核心线程数
    if (workerCountOf(c) < corePoolSize) {
        // 判断成立则执行addWorker()，初始化一条线程执行提交的任务command
        if (addWorker(command, true)) {
            return;
        }
        /**
         * 执行到此处有两个原因：
         * 1.线程池状态发生变化，已不再是RUNNING状态
         * 2.线程池内线程数已经达到或者超出核心线程数
         */
        c = ctl.get();
    }
    // 将任务放入队列，等待线程去取
    if (isRunning(c) && workQueue.offer(command)) {
        int recheck = ctl.get();
        if (!isRunning(recheck) && remove(command)) {
            // 若状态有变且工作对列移除任务成功，则调用拒绝执行策略
            reject(command);
        } else if (workerCountOf(recheck) == 0) {
            // 若线程池已无线程，则初始化一个不携带任务的线程，让它自动去工作队列中取任务执行
            addWorker(null, false);
        }
        /**
         * 执行到此处两个原因：
         * 1.线程池状态有变
         * 2.线程池核心线程数已满，工作队列已满，将继续增加线程数，以maximumPoolSize为上限
         */
    } else if (!addWorker(command, false)) {
        // 线程数超出最大上限或者线程池已关闭，拒绝执行任务
        reject(command);
    }
}

private final class Worker extends AbstractQueuedSynchronizer implements Runnable {
    // 运行任务的线程
    final Thread thread;

    // Worker第一个任务，为空不执行
    Runnable firstTask;

    // 任务完成数
    volatile long completedTasks;

    Worker(Runnable firstTask) {
        // 加锁，防止未初始化完成被运行
        // 在 runWorker() 方法中解锁
        setState(-1);
        this.firstTask = firstTask;
        this.thread = getThreadFactory().newThread(this);
    }
}
```

`addWorker()` 方法首先初始化一个 Worker 类，此类中包含一个 Thread 对象的引用，最终线程的启动是启动 Worker 下的 Thread（通过 `tread.start()`）。



## 双重校验锁实现对象单例

```java
public class Singleton {
    private volatile static Singleton instance;

    private Singleton() { }

    public static Singleton getInstance() {
        // 先判断对象是否已经实例过，没有实例化过才进入加锁代码
        if (instance == null) {
            // 类对象加锁
            synchronized (Singleton.class) {
                if (instance == null) {
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }
}
```

instance 采用 volatile 关键字修饰也是很有必要的，`instance = new Singleton();` 这段代码其实是分为三步执行：

1. 为 instance 分配内存空间。
2. 初始化 instance。
3. 将 instance 指向分配的内存地址。

但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1->3->2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。



## 线程交替打印

```java
static int num = 0;

private static void startTread(Lock lock, Condition condition, Condition nextCondition) {
    new Thread(() -> {
        lock.lock();
        try {
            while (true) {
                condition.await();
                if (num > 30) {
                    nextCondition.signal();
                    break;
                }
                System.out.println(num);
                num++;
                nextCondition.signal();
            }
        } catch (Exception ex) {
        } finally {
            lock.unlock();
        }
    }).start();
}

private static void start(Lock lock, Condition condition) {
    new Thread(()-> {
        lock.lock();
        try {
            condition.signal();
        } finally {
            lock.unlock();
        }
    }).start();
}

public static void main(String[] args) {
    Lock lock = new ReentrantLock();
    Condition condition1 = lock.newCondition();
    Condition condition2 = lock.newCondition();
    Condition condition3 = lock.newCondition();

    startTread(lock, condition1, condition2);
    startTread(lock, condition2, condition3);
    startTread(lock, condition3, condition1);

    start(lock, condition1);
}
```




