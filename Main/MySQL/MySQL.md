# MySQL

![image-20240513225243885](https://gitee.com/fushengshi/image/raw/master/image-20240513225243885.png)

MySQL 的架构共分为两层：

- Server 层：

  负责建立连接、分析和执行 SQL。MySQL 大多数的核心功能模块都在这实现，主要包括连接器，查询缓存、解析器、预处理器、优化器、执行器等。

  binlog 由 Server 层生成。

- 存储引擎层：

  负责数据的存储和提取。支持 InnoDB、MyISAM、Memory 等多个存储引擎，不同的存储引擎共用一个 Server 层。



## Buffer Pool

Innodb 存储引擎设计了一个缓冲池（Buffer Pool），来提高数据库的读写性能。

> 对比操作系统 Page Cache。

- 当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。
- 当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为**脏页**，最后由后台线程将脏页写入到磁盘。

![image-20240518172958594](https://gitee.com/fushengshi/image/raw/master/image-20240518172958594.png)

<img src="https://gitee.com/fushengshi/image/raw/master/image-20240517001057574.png" alt="image-20240517001057574" style="zoom:67%;" />

MySQL 启动的时候，InnoDB 会为 Buffer Pool 申请一片连续的内存空间，按照默认的 16 KB 的大小划分出页， Buffer Pool 中的页叫做缓存页。

### 预读机制

![image-20240517001930056](https://gitee.com/fushengshi/image/raw/master/image-20240517001930056.png)

为了更好的管理在 Buffer Pool 中的缓存页，InnoDB 为每一个缓存页都创建了一个控制块，控制块信息包括缓存页的表空间、页号、缓存页地址、链表节点等。

InnoDB 通过三种链表来管理缓页：

- Free List（空闲页链表）

  为了快速找到空闲的缓存页，可以使用链表结构，将空闲缓存页的控制块作为链表的节点，这个链表称为 Free 链表。

- Flush List（脏页链表）

  更新数据的时候不需要每次都要写入磁盘，而是将 Buffer Pool 对应的缓存页标记为脏页，由后台线程将脏页写入到磁盘。

  为了快速知道哪些缓存页是脏的，设计出 Flush 链表，链表的节点是控制块，和 Free 链表区别在于 Flush 链表的元素都是脏页。

  > 有一条记录需要更新的时候，InnoDB 引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以 redo log 的形式记录下来，InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里（WAL）。

- LRU List

  管理脏页和干净页。

  Buffer Pool 的大小是有限的，对于一些频繁访问的数据希望可以一直留在 Buffer Pool 中，而一些很少访问的数据可以在某些时机淘汰掉。

  Buffer Pool 空间不足时，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘。

  - 预读失效

    LRU 链表分为 young 和 old 两个区域。

    加入缓冲池的页，优先插入 old 区域，当页被访问被时，才进入 young 区域。

    > Linux 操作系统 Page Cache 实现两个了 LRU 链表：活跃 LRU 链表（active_list）和非活跃 LRU 链表（inactive_list）。

  - 缓存污染

    当页被访问第二次的时候且 old 区域停留时间超过 `innodb_old_blocks_time` 阈值（默认为1秒）时，才会将页插入到 young 区域，否则还是插入到 old 区域，目的是为了解决批量数据访问，大量热数据淘汰的问题。

    > Linux 操作系统 Page Cache 在内存页被访问第二次的时候，才将页从 inactive list 升级到 active list 里。



## 日志

- undo log（回滚日志）：

  是 Innodb 存储引擎层生成的日志，实现了事务中的**原子性**。

  主要用于事务回滚和 MVCC。

- redo log（重做日志）：

  Innodb 存储引擎层生成的日志，实现了事务中的**持久性**。

  主要用于掉电等故障恢复。

- binlog（归档日志）：

  Server 层生成的日志，主要用于数据备份和主从复制。

> 随机 I/O 要花费时间做昂贵的磁盘寻道，一般来说读写效率要比顺序 I/O 小两到三个数量级。
>
> 更新 binlog、redo log、undo log 都是在做顺序 I/O，而更新 datafile 和索引文件则是在做随机 I/O。为了减少随机 I/O 的发生，关系数据库已经做了很多的优化，比如写入时先写入内存，然后批量刷新到磁盘上，但随机 I/O 还是会发生。

### undo log

![image-20240516011740172](https://gitee.com/fushengshi/image/raw/master/image-20240516011740172.png)

undo log 主要有两个作用：

- 事务回滚（事务的原子性）

  当事务回滚时用于将数据恢复到修改前的样子。

  每当 InnoDB 引擎对一条记录进行操作（修改、删除、新增）时，要把回滚时需要的信息都记录到 undo log 里。

  - 在插入一条记录时，把这条记录的主键值记下来，回滚时把这个主键值对应的记录删掉。
  - 在删除一条记录时，把这条记录中的内容都记下来，回滚时把由这些内容组成的记录插入到表中。
  - 在更新一条记录时，把被更新的列的旧值记下来，回滚时把这些列更新为旧值。

- MVCC

  当读取记录时，若该记录被其他事务占用或当前版本对该事务不可见，则可以通过 undo log 读取之前的版本数据，以此实现非锁定读。

InnoDB 中 undo log 分为两种：

- insert undo log

  指在 `insert` 操作中产生的 undo log。

  因为 `insert` 操作的记录只对事务本身可见，对其他事务不可见，因此 undo log 可以在事务提交后直接删除，不需要进行 `purge` 操作。

- update undo log

  `update` 或 `delete` 操作中产生的 undo log。

  该 undo log 可能需要提供 MVCC 机制，因此不能在事务提交时就进行删除。提交时放入 undo log 链表，等待 `purge` 线程进行最后的删除。

#### 刷盘策略

undo log 和数据页的刷盘策略是一样的，需要**通过 redo log 持久化**。buffer pool 中有 undo 页，对 undo 页的修改也都会记录到 redo log。

- 由于数据库的 STEAL 策略，事务在更新一个页面后，数据库是可以把未提交的数据刷入磁盘的，这时如果发生崩溃，恢复时数据库就需要从 undo log 中找到数据库的更新前像。

  系统恢复后要进行事务恢复，对应事务回滚，事务需要从 undo log 中找到之前的值，如果事务不持久化 undo log（写这个 undo 操作的 redo log），对应事务就无法恢复到事务执行前的数据库状态，是不可恢复恢复的。

  > - FORCE 策略
      >
      >   当事务提交后，要求变动数据必须同时完成写入则称为 FORCE，如果不强制变动数据必须同时完成写入则称为 NO-FORCE。
  >
  > - STEAL 策略
      >
      >   在事务提交前，允许变动数据提前写入则称为 STEAL。磁盘上可能包含未提交的数据，因此系统需要记录 undo log。
      >
      >   **redo log 会每秒刷盘，提交事务时也会刷盘**，数据页和 undo 页都是靠这个机制持久化的。

- 事务执行过程中数据库宕机，没有持久化的事务的变更不需要使用 undo log 回滚。



### redo log

当有一条记录需要更新的时候，InnoDB 引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以 redo log 的形式记录下来。InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这就是 WAL（Write-Ahead Logging）技术。

redo log 是物理日志，记录了某个数据页做了什么修改，**对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新**，每当执行一个事务就会产生这样的一条或者多条物理日志。

- 事务的持久性

  redo log 结合 WAL 技术，InnoDB 就可以保证即使数据库发生异常重启，之前已提交的记录都不会丢失。

  事务提交时只要先将 redo log 持久化到磁盘即可，可以不等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，MySQL 重启后可以根据 redo log 的内容，将所有数据恢复到最新的状态。

- 写操作随机写变成了顺序写

  每更改一次缓存缓存持久化到磁盘中时，系统就会根据指针的位置，随机的存储在磁盘中，当读取该数据时就要随机 I/O 扫描全盘进行寻找，浪费性能。

  每更改一次缓存变成日志信息存储在磁盘中，由于磁盘中的文件是一片连续的 I/O，后台程序在进行日志读取时，不需要扫描全盘，同时可以在后台将日志翻译成连续的数据空间，连续 I/O 读取效率高。

#### 刷盘策略

执行一个事务的过程中，产生的 redo log 也不是直接写入磁盘的，因为这样会产生大量的 I/O 操作，而且磁盘的运行速度远慢于内存。redo log 有自己的缓存 redo log buffer（InnoDB 引擎的 log buffer 中），每当产生一条 redo log 时，会先写入到 redo log buffer，后续持久化到磁盘。

redo log 是循环写的方式，相当于一个环形，InnoDB 用 write pos 表示 redo log 当前记录写到的位置，用 checkpoint 表示当前要擦除的位置。一次 checkpoint 的过程就是脏页刷新到磁盘中变成干净页，然后标记 redo log 哪些记录可以被覆盖的过程。

刷盘时机：

- MySQL 正常关闭

- 写入量超过阈值

  当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘。

- 后台线程

  InnoDB 的**后台线程每隔 1 秒**，将 redo log buffer 持久化到磁盘。

  > 每秒刷盘会将未提交的事务进行持久化（Steal 策略），因此要同时持久化 undo log 用于事务恢复时的回滚。

- 事务提交

  **每次事务提交时**都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘，可由 `innodb_flush_log_at_trx_commit ` 参数控制：

  - 参数为 0

    每次事务提交时 ，将 redo log 留在 redo log buffer 中，不会主动触发写入磁盘的操作。

    InnoDB 的后台线程每隔 1 秒会把缓存在 redo log buffer 中的 redo log ，通过调用 `write()` 写到操作系统的 Page Cache，然后调用 `fsync()` 持久化到磁盘。

    MySQL 进程的崩溃会导致上一秒钟所有事务数据的丢失。

  - 参数为 1（默认）

    每次事务提交时，将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘。

    可以保证 MySQL 异常重启之后数据不会丢失。

  - 参数为 2

    每次事务提交时，都只是缓存在 redo log buffer 里的 redo log `write()`写到操作系统的 Page Cache（redo log 文件）。

    InnoDB 的后台线程每隔 1 秒调用 `fsync()`，将缓存在操作系统中 Page Cache 里的 redo log 持久化到磁盘。

    MySQL 进程的崩溃并不会丢失数据，只有在操作系统崩溃或者系统断电的情况下，上一秒钟所有事务数据才可能丢失。

  <img src="https://gitee.com/fushengshi/image/raw/master/image-20240518175023991.png" alt="image-20240518175023991"  />

### binlog

MySQL 在完成一条更新操作后，Server 层还会生成一条 binlog。事务提交的时候会将该事物执行过程中产生的所有 binlog 统一写入 binlog 文件，用于备份恢复、主从复制。binlog 文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作。

> undo log 和 redo log 这两个日志都是 InnoDB 存储引擎生成的。

binlog 有 3 种格式类型：

- STATEMENT（MySQL 5.7.7 以前默认）

  每一条修改数据的 SQL 都会被记录到 binlog 中（相当于记录了逻辑操作，可以称为逻辑日志），主从复制中 Slave 端再根据 SQL 语句重现。

  STATEMENT 有动态函数的问题，比如 uuid 或者 now 函数，主库上执行的结果不是在从库执行的结果。

- ROW（MySQL 5.7.7 之后默认）

  记录行数据最终被修改成什么样，不会出现 STATEMENT 下动态函数的问题。

  ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已。

- MIXED

  包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式。



#### 刷盘策略

![image-20240518224928084](https://gitee.com/fushengshi/image/raw/master/image-20240518224928084.png)

- 事务执行过程中，先把日志写到 binlog cache。

  MySQL 给每个线程分配了一片内存用于缓冲 binlog ，该内存叫 binlog cache（Server 层的 cache）。

- **事务提交的时候**，通过 `write()` 系统调用把日志写入到 binlog 文件内核缓冲区 Page Cache。

  此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 Page Cache，内核缓冲区的数据根据 `sync_binlog` 参数通过 `fsync()` 写入到硬盘：

  - sync_binlog = 0（默认）

    事务提交的时候不 `fsync()`，后续交由操作系统决定何时将数据持久化到磁盘。

    一旦主机发生异常重启，还没持久化到磁盘的数据就会丢失。

  - sync_binlog = 1

    事务提交的时候都会马上执行 `fsync()`。

  - sync_binlog = N（N > 1）

    事务提交的时候，累积 N 个事务后再 `fsync()`。

    如果能容少量事务的 binlog 日志丢失的风险，为了提高写入的性能，一般会 sync_binlog 设置为 100~1000 中的某个数值。

  > 对比 Redis AOF 日志刷盘策略。



### 两阶段提交

事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态，这样就造成两份日志之间的逻辑不一致。两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态。

两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是准备（Prepare）阶段和提交（Commit）阶段。

- Pepare 阶段：

  将 XID（内部 XA 事务的 ID）写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘（innodb_flush_log_at_trx_commit = 1` 的作用）。

  对于处于 Prepare 阶段的 redo log，即可以提交事务也可以回滚事务，取决于是否能在 binlog 中查找到与 redo log 相同的 XID，如果有就提交事务，如果没有就回滚事务。这可以保证 redo log 和 binlog 这两份日志的一致性。

- Commit 阶段：

  把 XID 写入到 binlog，然后将 binlog 持久化到磁盘（`sync_binlog = 1` 的作用），接着调用引擎的提交事务接口。

  将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中，因为只要 binlog 写磁盘成功，即使 redo log 的状态还是 prepare 一样会被认为事务已经执行成功。

> redo log 可以在事务没提交之前持久化到磁盘（Steal 策略），但是 binlog 必须在事务提交之后，才可以持久化到磁盘。

### 组提交

MySQL 引入了 binlog 组提交（group commit）机制，当有多个事务提交的时候，会将多个 binlog 刷盘操作合并成一个，从而减少磁盘 I/O 的次数。

将两阶段提交 commit 阶段拆分为三个过程：

- flush 阶段

  多个事务按进入的顺序将 binlog 从 binlog cache 写入文件（不刷盘，写入 Page Cache）。

- sync 阶段

  对 binlog 文件做 `fsync()` 操作（多个事务的 binlog 合并一次刷盘）。

- commit 阶段

  各个事务按顺序做 InnoDB commit 操作。



## 索引

物理存储的角度来看，索引分为聚簇索引（主键索引）、二级索引（辅助索引）。

- 主键索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里。
- 二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。

查询的数据不在二级索引里，就会先检索二级索引找到对应的叶子节点，获取到主键值后，然后再检索主键索引查询到数据，这个过程是**回表**。

在查询时使用了二级索引，如果查询的数据能在二级索引里查询的到，那么就不需要回表，这个过程是**覆盖索引**。

### B+ Tree

B+Tree 是一种多叉树，叶子节点才存放数据，非叶子节点只存放索引，而且每个节点里的数据是按主键顺序存放的。每一层父节点的索引值都会出现在下层子节点的索引值中，因此在叶子节点中，包括了所有的索引值信息，并且每一个叶子节点都有两个指针，分别指向下一个叶子节点和上一个叶子节点，形成一个双向链表。

<img src="https://gitee.com/fushengshi/image/raw/master/image-20240514004935008.png" alt="image-20240514004935008" style="zoom: 67%;" />

#### 数据存储

InnoDB 的数据是按数据页为单位来读写的，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。

InnoDB 里的 B+ 树中的**每个节点都是一个数据页**。

数据页：

<img src="https://gitee.com/fushengshi/image/raw/master/image-20240514011036472.png" alt="image-20240514011036472" style="zoom: 67%;" />

> File Header（38 byte）、Page Header（56 Byte）、Infimum + Supermum（26 byte）、File Trailer（8byte）, 再加上页目录，大概 1k 左右。
>

- File Header 中有两个指针，分别指向上一个数据页和下一个数据页，连接起来的页相当于一个双向的链表。

- 数据页中的用户记录（User Records）按照主键顺序组成单向链表。

  > 行格式的记录头信息中 next_record：下一条记录的位置。记录与记录之间是通过链表组织的。

- 页目录就是由多个槽组成的，槽相当于分组记录的索引。

  因为记录是按照主键值从小到大排序的，通过槽查找记录时可以使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后再遍历槽内的所有记录，找到对应的记录，无需从最小记录开始遍历整个页中的记录链表。

![image-20240514011231551](https://gitee.com/fushengshi/image/raw/master/image-20240514011231551.png)

```c
struct btree_node
{
	int num; //当前树关键字个数	
	int data[M]; //保存关键字的数组
	struct btree_node *child[M]; //指向孩子节点的指针 //指针在InnoDB中为6字节
	int leaf; //指示是否叶子结点，0，否，1，是
};
```

B+ 树与 B 树差异：

- 叶子节点（最底部的节点）才会存放实际数据（索引+记录），非叶子节点只会存放索引。
- 所有索引都会在叶子节点出现，叶子节点之间构成一个有序链表。
- **非叶子节点的索引也会同时存在在子节点中（所有非叶子节点都是冗余索引）**，并且是在子节点中所有索引的最大（或最小）。
- 非叶子节点中有多少个子节点，就有多少个索引。

B+ 树优点：

- B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，B+ 树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更低，查询底层节点的磁盘 I/O 次数会更少。
- B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化。
- B+ 树叶子节点之间用链表连接了起来，有利于范围查询。



### 联合索引

通过将多个字段组合成一个索引，该索引就被称为联合索引。

> (a, b, c) 联合索引，是先按 a 排序，在 a 相同的情况再按 b 排序，在 b 相同的情况再按 c 排序。**b 和 c 是全局无序，局部相对有序的**。

#### 最左匹配原则

使用联合索引时，存在**最左匹配原则**，也就是按照最左优先的方式进行索引的匹配。在使用联合索引进行查询的时候，如果不遵循最左匹配原则，联合索引会失效，无法利用索引快速查询的特性。

- 最左前缀索引

  like 只用 'string%'，语句中的 = 和 in 会动态调整顺序。

- 无法使用索引

  != 、is null 、 or、>< 、in 、not in。

  > 对于 >=、<=、BETWEEN、like 前缀匹配的范围查询，并不会停止匹配。

范围查询右边失效原理

```sql
select * from xxx where a>1 and b=2
```

- a 字段在 B+ 树上是有序的，所以可以用二分查找法定位到 1，然后将所有大于 1 的数据取出来，a 可以用到索引。

- b 有序的前提是 a 是确定的值， a 大于 1 的 B+ 树里，b 字段是无序的，所以 b 不能在无序的 B+ 树里用二分查找来查询，b 用不到索引。

### 覆盖索引

覆盖索引是指 SQL 中 query 的所有字段，在索引 B+Tree 的叶子节点上都能找得到的那些索引，从二级索引中查询得到记录，而不需要通过聚簇索引查询获得，可以避免回表的操作。

### 索引下推

索引下推（index condition pushdown）， 可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

索引下推能够减少二级索引在查询时的回表操作，提高查询的效率，因为它将 Server 层部分负责的事情，交给存储引擎层去处理了。

存储引擎定位到二级索引后，先不执行回表操作，而是先判断一下该索引中包含的列的条件是否成立。如果条件不成立，则直接跳过该二级索引。如果成立，则执行回表操作，将完成记录返回给 Server 层。



## 事务

- 原子性（Atomicity）

  一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态。

  > 原子性是通过 undo log（回滚日志） 来保证的。

- 一致性（Consistency）

  是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。

  > 一致性是通过持久性 + 原子性 + 隔离性来保证。

- 隔离性（Isolation）

  数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。

  >隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的。

- 持久性（Durability）

  事务处理结束后，对数据的修改是永久的，即便系统故障也不会丢失。

  > 持久性是通过 redo log （重做日志）来保证的。

### 隔离级别

- 读未提交（read uncommitted）

  指一个事务还没提交时，它做的变更就能被其他事务看到。

  可能发生脏读、不可重复读和幻读现象。

  因为可以读到未提交事务修改的数据，所以直接读取最新的数据。

- 读提交（read committed）

  指一个事务提交之后，它做的变更才能被其他事务看到。

  可能发生不可重复读和幻读现象，但是不可能发生脏读现象。

  **在每个语句执行前重新生成一个 Read View**。

- 可重复读（repeatable read）（MySQL InnoDB 默认）

  指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的。

  可能发生幻读现象（MySQL InnoDB 很大程度上避免幻读现象），但是不可能脏读和不可重复读现象。

  > 一个事务内进行了多次读取，数据总量不一致。

  **启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View**。

- 串行化（serializable）

  会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。

  脏读、不可重复读和幻读现象都不可能会发生。

  通过加读写锁的方式来避免并行访问。

MySQL InnoDB 引擎的默认隔离级别虽然是可重复读，但是很大程度上避免幻读现象：

- 快照读（普通 select 语句）

  通过 MVCC 方式解决了幻读。

  因为可重复读隔离级别下，事务执行过程中看到的数据和这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，避免幻读了问题。

- 当前读（`select ... for update` 等语句）

  通过 next-key lock（记录锁 + 间隙锁）方式解决了幻读。

  因为当执行 `select ... for update` 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，避免了幻读问题。

  > 发生幻读场景：
  >
  > - 快照读事务 A 更新了一条事务 B 插入的记录。
  > - 如果事务开启后，并没有执行当前读，而是先快照读。



### MVCC

MVCC（Multi-Version Concurrency Control）是一种并发控制机制，用于在多个并发事务同时读写数据库时保持数据的一致性和隔离性。它是通过在每个数据行上维护多个版本的数据来实现的。当一个事务要对数据库中的数据进行修改时，MVCC 会为该事务创建一个数据快照，而不是直接修改实际的数据行。

MVCC 的实现依赖于：行格式隐藏字段、Read View、undo log。在内部实现中，InnoDB 通过数据行的 `DB_TRX_ID` 和 Read View 来判断数据的可见性，如不可见，则通过数据行的 `DB_ROLL_PTR` 找到 undo log 中的历史版本。

#### Read View

<img src="https://gitee.com/fushengshi/image/raw/master/image-20240515225938465.png" alt="image-20240515225938465" style="zoom:80%;" />

- `min_trx_id` ：

  创建 Read View 时当前数据库中活跃事务中事务 id 最小的事务，也就是 m_ids 的最小值。

  如果记录的 trx_id 值小于 Read View 中的 `min_trx_id` 值，表示这个版本的记录是在创建 Read View 前已经提交的事务生成的，所以该版本的记录对当前事务可见。

- `max_trx_id `：

  创建 Read View 时当前数据库中应该给下一个事务的 id 值，也就是全局事务中最大的事务 id 值 + 1。

  如果记录的 trx_id 值大于等于 Read View 中的 `max_trx_id` 值，表示这个版本的记录是在创建 Read View 后才启动的事务生成的，所以该版本的记录对当前事务不可见。

- `m_ids` ：

  指的是在创建 Read View 时，当前数据库中活跃事务（启动了但还没提交的事务）的事务 id 列表。

  如果记录的 trx_id 值在 Read View 的 `min_trx_id` 和 `max_trx_id` 之间，需要判断 trx_id 是否在 m_ids 列表中：

  - 如果记录的 trx_id 在 `m_ids` 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务不可见。
  - 如果记录的 trx_id 不在  `m_ids` 列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。

- `creator_trx_id `：

  指的是创建该 Read View 的事务的事务 id。



## 锁

**加锁的对象是针对索引**，InnoDB 只有通过索引条件检索数据才使用行级锁，否则 InnoDB 将使用表锁。

>  不带索引对所有记录加上 next-key 锁（记录锁 + 间隙锁），相当于锁了整张表。
>
> 在执行 update、delete、select ... for update 等具有加锁性质的语句，一定要检查语句是否走了索引。

### 锁结构

<img src="https://gitee.com/fushengshi/image/raw/master/image-20240516025143645.png" alt="image-20240516025143645" style="zoom:67%;" />

Innodb 锁结构通过 lock_sys 管理，所有的行锁 lock_t 对象都插入 hash 表中，通过维护 hash 表管理行锁对象，hash 表的 key 值通过页号（space_id，page_no）计算得到。

```c
lock_sys
{
    hash_table_t*   rec_hash;     // 行锁hash表
    srv_slot_t* waiting_threads;  // 等待对象数组
}

lock_rec_t
{
    ulint   space;    // 表空间编号
    ulint   page_no;  // 数据页编号
    ulint   n_bits;   // 数据页包含的记录
    byte   bitmap[1+n_bits/8]  // bitmap数组
};
```

innodb 行锁采用位图存储，理论上一个记录只需要一个 bit 位。锁的基本单位是行，但锁是通过事务和页来进行管理和组织，创建锁的实例是 lock_t，一个 lock_t 实例对应于一个索引页面的所有记录。



### 表级锁

- 意向锁

  - 在使用 InnoDB 引擎的表里对某些记录加上共享锁之前，需要先在表级别加上一个意向共享锁。
  - 在使用 InnoDB 引擎的表里对某些纪录加上独占锁之前，需要先在表级别加上一个意向独占锁。

  当执行插入、更新、删除操作，需要先对表加上意向独占锁，然后对该记录加独占锁。

  意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（lock tables ... read）和独占表锁（lock tables ... write）发生冲突。

  **意向锁的目的是为了快速判断表里是否有记录被加锁**。加独占表锁时，直接查该表是否有意向独占锁，如果有就意味着表里已经有记录被加了独占锁，这样就不用去遍历表里的记录。

### 行级锁

- 共享锁（S锁）满足读读共享，读写互斥。
- 独占锁（X锁）满足写写互斥、读写互斥。

在读已提交隔离级别下，行级锁的种类只有记录锁。

在可重复读隔离级别下，行级锁的种类有：

- Record Lock（记录锁）

  Record Lock 称为记录锁，锁住的是一条记录。

- Gap Lock（间隙锁）

  Gap Lock 称为间隙锁，只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别下幻读的现象。

  **间隙锁之间是兼容的**，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系。

  表中有一个范围 id 的 (3, 5) 的间隙锁，其它事务无法插入 id = 4 记录。

- Next-Key Lock（临键锁）

  Next-Key Lock 称为临键锁，是 Record Lock + Gap Lock 的组合，锁定一个范围并且锁定记录本身。

  next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时是会被阻塞的。避免其他事务执行增、删、改时导致幻读的问题。

  表中有一个范围 id 的 (3, 5] 的临键锁，其它事务无法插入 id = 4 记录，无法删除和修改 id = 5 记录。



### MySQL 加行级锁

普通的 select 语句是不会对记录加锁的（串行化隔离级别除外），锁定读、update、delete 操作会加行级锁。

```sql
// 对读取的记录加共享锁(S型锁)
select ... lock in share mode;

// 对读取的记录加独占锁(X型锁)
select ... for update;

// 对操作的记录加独占锁(X型锁)
update table .... where id = 1;

// 对操作的记录加独占锁(X型锁)
delete from table where id = 1;
```

> 事务提交，锁就会释放，要加上 begin 或者 start transaction 开始事务。

加锁的对象是索引，加锁的基本单位是临键锁。

在能使用记录锁或者间隙锁能避免幻读现象的场景，临键锁会退化成记录锁或者间隙锁。

- 唯一索引等值查询

  - 查询记录存在，在索引树上定位到这一记录，临键锁会退化成记录锁。
  - 查询记录不存在，索引树找到第一条大于该查询记录的记录后，将该记录的索引中的临键锁退化成间隙锁。

- 非唯一索引等值查询

  - 查询记录存在。

    在扫描的过程中，对扫描到的二级索引记录加的是临键锁，对于第一个不符合条件的二级索引记录，该二级索引的 临键锁会退化成间隙锁。

    在符合查询条件的记录的主键索引上加记录锁。

  - 查询记录不存在，扫描到第一条不符合条件的二级索引记录，该二级索引的临键锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁。

- 唯一索引范围查询

  唯一索引在满足一些条件的时候，索引的临键锁退化为间隙锁或者记录锁。

- 非唯一索引范围查询

  非唯一索引范围查询，索引的临键锁不会退化为间隙锁和记录锁。



### Insert 语句加锁

- 当事务需要加锁的时，如果这个锁不可能发生冲突，InnoDB 会跳过加锁环节，这种机制称为隐式锁。

  隐式锁是 InnoDB 实现的一种**延迟加锁机制**，其特点是只有在可能发生冲突时才加锁，从而减少了锁的数量，提高了系统整体性能。

- 记录之间加有间隙锁

  每插入一条新记录，都需要看一下待插入记录的下一条记录上是否已经被加了间隙锁，如果已加间隙锁，此时会生成一个插入意向锁，然后锁的状态设置为等待状态，Insert 语句会被**阻塞**。

- 唯一键冲突

  如果在插入新记录时，插入了一个与已有的记录的主键或者唯一二级索引列值相同的记录，此时插入就会失败，然后对于这条记录加上 S 型记录锁。

  - 如果主键索引重复，插入新记录的事务会给已存在的主键值重复的聚簇索引记录添加 S 型记录锁。
  - 如果唯一二级索引重复，插入新记录的事务都会给已存在的二级索引列值重复的二级索引记录添加 S 型 next-key 锁。


两个事务的加锁过程：

- 事务 A 先插入记录，可以插入成功，此时对应的唯一二级索引记录被隐式锁保护，还没有实际的锁结构。

- 事务 B 在插入二级索引记录时会遇到重复的唯一二级索引列值，此时事务 B 想获取一个 S 型 next-key 锁，但是事务 A 并未提交，事务 A 插入的记录上的隐式锁会变显示锁且锁类型为 X 型的记录锁，所以事务 B 向获取 S 型 next-key 锁时会遇到锁冲突，事务 B 进入阻塞状态。

> 插入意向锁
>
> 一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁（next-key lock 也包含间隙锁）。如果有的话，插入操作就会发生阻塞，直到拥有间隙锁的那个事务提交为止（释放间隙锁的时刻），在此期间会生成一个插入意向锁，表明有事务想在某个区间插入新记录，但是现在处于等待状态。
>
> 插入意向锁名字虽然有意向锁，但是它不是意向锁，它是一种特殊的间隙锁，**属于行级别锁**。尽管插入意向锁也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁。



### 死锁

两个事务即使生成的间隙锁的范围是一样的，也不会发生冲突，因为间隙锁目的是为了防止其他事务插入数据，因此间隙锁与间隙锁之间是相互兼容的。

在执行插入语句时，如果插入的记录在其他事务持有间隙锁范围内，插入语句就会被阻塞，因为插入语句在碰到间隙锁时，会生成一个插入意向锁，然后插入意向锁和间隙锁之间是互斥的关系。如果两个事务分别向对方持有的间隙锁范围内插入一条记录，而插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待。

#### 规避死锁

死锁只有同时满足**互斥**、**持有并等待**、**不可剥夺**、**循环等待**时才会发生。

- 持有并等待

  一次性申请所有的资源，这样就不存在等待了。

- 不可剥夺

  占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。

- 循环等待

  可以靠按序申请资源来预防，也就是所谓的资源有序分配原则，让资源的申请和使用有线性顺序，申请的时候可以先申请资源序号小的，再申请资源序号大的。



## 高可用

### 主从复制

![image-20240720200611340](https://gitee.com/fushengshi/image/raw/master/image-20240720200611340.png)

详细过程：

- 主库写入 binlog：

  MySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端操作成功的响应。

- 从库同步 binlog：

  从库会创建一个专门的 I/O 线程，**连接主库的 log dump 线程**，来接收主库的 binlog 日志，再把 binlog 信息**写入 relay log**（中继日志），再返回给主库复制成功的响应。

- 从库回放 binlog：

  从库创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据（再执行一遍 SQL），最终实现主从的数据一致性。

主从复制模型：

- 同步复制

  MySQL 主库提交事务的线程要等待所有从库的复制成功响应，才返回客户端结果。性能很差，因为要复制到所有节点才返回响应。可用性也很差，主库和所有从库任何一个数据库出问题，都会影响业务。

- 异步复制（默认）

  MySQL 主库提交事务的线程并不会等待 binlog 同步到各从库，就返回客户端结果。

  这种模式一旦主库宕机，数据就会发生丢失。


- 半同步复制

  事务线程不用等待所有的从库复制成功响应，只要一部分复制成功响应回来就行。比如一主二从的集群，只要数据成功复制到任意一个从库上，主库的事务线程就可以返回给客户端。

  这种半同步复制的方式，兼顾了异步复制和同步复制的优点，即使出现主库宕机，至少还有一个从库有最新的数据，不存在数据丢失的风险。

- 增强半同步复制：在半同步复制的基础上，主节点收到响应后才提交事务，数据一致性会比半同步好，但性能稍差。

- 延迟复制：从节点延迟一段时间恢复数据，这样即使发生误操作也可以进行回滚数据。

> 很多组件都会使用到主从复制：
>
> - Redis 也是通过主从复制实现读写分离。
> - Elasticsearch 中存储的索引分片复制到多个节点中。
> - 写入到 HDFS 中文件复制到多个 DataNode 中。



### 主从切换

binlog 上会记录主节点写操作的时间，从节点会维护一个 `seconds_behind_master` 来记录主从延迟的时间。

在进行主从切换时，每个从节点同步数据的日志偏移量都不同，一般会找最新偏移量的从节点为新的主节点。这个偏移量是需要运维去定位的。通过 **GTID 全局事务 ID**，binlog中每个事务有对应的 GTID 则可以通过 GTID 自动定位偏移量，不用手动定位。

- 可靠策略

  等到旧的从节点完成所有的数据恢复（即 `seconds_behind_master` 为 0）才成为主节点，提供写服务。

- 可用策略

  立即将从节点设置为新的主节点提供读写服务，某些场景下可能导致数据不一致。

#### 主从延迟

由于使用异步复制，主从之间的数据一致性会存在一定的延迟。网络通信忽略不计，成本最大的就是从机 SQL 线程解析日志恢复数据的过程，缩短延迟方案：

- 增加从库数量

  增加从库数量可以增加数据同步的速度和可靠性，同时也能减少每个从库的负担，提高从库响应速度。

- 调整 redo log 和 bin log 刷盘策略，增强 I/O。

- Canal 监听（通知改为监听）。

- 从库并行复制

  - MySQL 5.6 开始有了多个 SQL 线程的概念，支持的粒度是按库并行（基于 Schema）。

    不同 schema 下的表并发提交时的数据不会相互影响，即从库可以对 relay log 中不同的 schema各分配一个类似 SQL 线程功能的线程重放 relay log 中主库已经提交的事务，保持数据与主库一致。

  - MySQL 5.7 引入了基于组提交的并行复制。

    利用 binlog 的组提交（group commit）机制，一个组提交的事务都是可以并行执行的，因为能够在同一组里提交的事务，一定不会修改同一行（MySQL 的锁机制，事务已经通过锁冲突的检验）。

如果某些操作对数据的实时性要求比较苛刻，需要反映实时最新的数据，比如涉及金钱的金融类系统、在线实时系统或者是写入之后马上又读的业务，解决问题核心思想是尽量不去从库中查询信息。

- 数据冗余

  发送消息时发送处理需要的所有信息，借此避免从数据库中重新查询数据。

- 使用缓存

  在同步写数据库的同时把数据写入到 Memcached 缓存，获取信息时优先查询缓存。

- 查询主库

  明确查询的量级不会很大，是在主库的可承受范围之内，否则会对主库造成比较大的压力。




### 主从选举机制

MySQL 主从复制中的选举算法是基于 **Raft算法** 实现的。

> 对比 Redis 哨兵选举 Leader。

- 从节点向其他从节点发选举请求，请求其他节点投票支持自己成为主节点。

- 其他从节点收到选举请求后，如果没有投票支持其他从节点，则投票支持请求发起节点成为主节点。

- 如果有多个节点投票支持同一个节点，则选举流程结束，该节点成为新的主节点。



## 分库分表

分库是将数据库中的数据分散到不同的数据库上。

- 垂直分库：把单一数据库按照业务进行划分，不同的业务使用不同的数据库，进而将一个数据库的压力分担到多个数据库。

- 水平分库：把同一个表按一定规则拆分到不同的数据库中，每个库可以位于不同的服务器上，这样就实现了水平扩展，解决了单表的存储和性能瓶颈的问题。

分表是对单表的数据进行拆分。

- 垂直分表：对数据表列的拆分，把一张列比较多的表拆分为多张表。

- 水平分表：对数据表行的拆分，把一张行比较多的表拆分为多张表，可以解决单一表数据量过大的问题。

> NoSQL 数据库例如 Hbase，MongoDB 都提供 auto sharding 的特性。

![image-20240616172419169](https://gitee.com/fushengshi/image/raw/master/image-20240616172419169.png)

遇到下面几种场景可以考虑分库分表：

- 单表的数据达到千万级别以上，数据库读写速度比较缓慢。
- 数据库中的数据占用的空间越来越大，备份时间越来越长。
- 应用的并发量太大（应该优先考虑其他性能优化方法，而非分库分表）。

为了降低实现的复杂度，业界涌现了很多数据库中间件来解决数据库的访问问题：

- 以代码形式内嵌运行在应用程序内部

  一种数据源的代理，它的配置管理着多个数据源，每个数据源对应一个数据库，可能是主库，可能是从库。当有一个数据库请求时，中间件将 SQL 语句发给某一个指定的数据源来处理，然后将处理结果返回。

  - Sharding-JDBC

    由当当网开源的一款轻量级 Java 框架，它不改变应用的 JDBC 和 Spring Data JPA 编程方式，而是作为一个 JDBC 层面的代理，实现了数据源的自动切换和分片逻辑。Sharding-JDBC 支持复杂的 SQL 语句，包括分页、排序、聚合函数等，同时提供了一套完整的分库分表解决方案，包括数据路由、读写分离、分布式事务、数据加密等。

  - TDDL

    阿里巴巴集团内部使用的一款高性能、高可用的数据库访问层，主要用于解决大规模分布式系统中的数据库访问问题。TDDL 提供了数据分片、读写分离、数据库连接池等功能，能够支持复杂的 SQL 语句重写和优化，适用于大型互联网公司的高并发场景。

- 单独部署的代理层方案

  中间件部署在独立的服务器上，业务代码如同在使用单一数据库一样使用它，实际上它内部管理着很多的数据源，当有数据库请求时，它会对 SQL 语句做必要的改写，然后发往指定的数据源。

  - Mycat 是一款开源的数据库中间件，它位于应用程序和数据库之间，作为代理服务器，实现了对后端数据库集群的统一管理和调度。Mycat 支持 SQL 解析、路由、分片、读写分离、数据加密等功能，能够透明地对应用程序隐藏底层数据库的复杂性。与客户端分片不同，Mycat将分片逻辑集中在中间件层，减轻了应用端的负担，同时也简化了应用的开发和维护。
  - 360 开源的 Atlas。
  - 美团开源的基于 Atlas 开发的 DBProxy。



### 分片算法

分片算法主要解决了数据被水平分片之后，数据究竟该存放在哪个表的问题。

> 对比负载均衡算法。

- 哈希分片

  求指定分片键的哈希，然后根据哈希值确定数据应被放置在哪个表中。哈希分片比较适合随机读写的场景，不太适合经常需要范围查询的场景。哈希分片可以使每个表的数据分布相对均匀，但对动态伸缩（例如新增一个表或者库）不友好。

- 范围（Range）分片

  按照特定的范围区间（比如时间区间、ID 区间）来分配数据。范围分片适合需要经常进行范围查找且数据分布均匀的场景，不太适合随机读写的场景（数据未被分散，容易出现热点数据的问题）。

  由于 Range 分片是按照业务特性进行的分片策略，所以可以对热点数据做垂直扩展，即提升单机处理能力。

- 映射表分片

  使用一个单独的表（称为映射表，分片元数据表）来存储分片键和分片位置的对应关系。

  映射表分片策略可以支持任何类型的分片算法。

  这种方式需要维护额外的表，实现起来复杂，需要二次查询，需要保证分片元数据服务的高可用。可以通过缓存进行提速。

- 一致性哈希分片

  将哈希空间组织成一个环形结构，将分片键和节点（数据库或表）都映射到这个环上，然后根据顺时针的规则确定数据或请求应该分配到哪个节点上，解决了传统哈希对动态伸缩不友好的问题。

### 分库分表问题

- join 操作

  同一个数据库中的表分布在了不同的数据库中，导致无法使用 join 操作。这样就导致我们需要手动进行数据的封装，比如你在一个数据库中查询到一个数据之后，再根据这个数据去另外一个数据库中找对应的数据。

- 事务问题

  同一个数据库中的表分布在了不同的数据库中，如果单个操作涉及到多个数据库，数据库自带的事务就无法满足要求，需要分布式事务。

- 分布式 ID

  分库之后， 数据遍布在不同服务器上的数据库，数据库的自增主键没办法满足生成的主键唯一，需要分布式 ID 。

- 跨库聚合查询问题

  分库分表会导致常规聚合查询操作，如 group by，order by 等变得异常复杂。这些操作需要在多个分片上进行数据汇总和排序，而不是在单个数据库上进行。

  为了实现这些操作，需要编写复杂的业务代码，或者使用中间件来协调分片间的通信和数据传输。这样会增加开发和维护的成本，以及影响查询的性能和可扩展性。

  > 可以考虑其他的存储方案，比如：
  >
  > - 聚合查询使用频繁时，可以将聚合查询的数据同步到 ES 中，或者将计数的数据单独存储在一张表里。
  >
  > - 如果是每日定时生成的统计类报表数据，也可以将数据同步到 HDFS 中，然后用一些大数据技术来生成报表。



# 附录

## SQL 执行流程

- 连接器：建立连接，管理连接、校验用户身份。

  MySQL 是基于 TCP 协议进行传输的。

- 查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。

  > MySQL 8.0 已删除该模块。

- 解析 SQL：

  通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型。

- 执行 SQL：

  - 预处理阶段：检查表或字段是否存在，将 `select *` 中的 `*` 符号扩展为表上的所有列。
  - 优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划。
  - 执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端。



## 表空间

表空间由段（segment）、区（extent）、页（page）、行（row）组成，InnoDB 存储引擎的逻辑存储结构大致如下图：

<img src="https://gitee.com/fushengshi/image/raw/master/image-20240513234913401.png" alt="image-20240513234913401" style="zoom:67%;" />

- 行（row）

  数据库表中的记录都是按行（row）进行存放的，每行记录根据不同的行格式，有不同的存储结构。

- 页（page）

  InnoDB 的数据是按页为单位来读写的，默认每个页的大小为 16 KB。

  页是 InnoDB 存储引擎磁盘管理的最小单元。页的类型有很多，常见的有数据页、undo 日志页、溢出页等等。数据表中的行记录是用数据页来管理的。

  > 磁盘读写的最小单位是扇区，扇区的大小只有 512 B 大小，
  >
  > 操作系统一次会读写多个扇区，所以操作系统的最小读写单位是块（Block）。Linux 中的块大小为 4 KB，也就是一次磁盘 I/O 操作会直接读写 8 个扇区。

- 区（extent）

  B+ 树中每一层都是通过双向链表连接起来的，如果是以页为单位来分配存储空间，那么链表中相邻的两个页之间的物理位置并不是连续的，磁盘查询时会有大量的随机 I/O。

  在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区（extent）为单位分配。每个区的大小为 1 MB，对于 16 KB 的页来说，连续的 64 个页会被划为一个区，使得链表中相邻的页的物理位置也相邻，就能使用顺序 I/O 了。

- 段（segment）

  表空间是由各个段（segment）组成的，段是由多个区（extent）组成的。段一般分为数据段、索引段和回滚段等。

  - 索引段：存放 B+ 树的非叶子节点的区的集合。

  - 数据段：存放 B+ 树的叶子节点的区的集合。

  - 回滚段：存放的是回滚数据的区的集合。

    > MVCC 利用了回滚段实现了多版本查询数据。

### 行溢出

MySQL 中磁盘和内存交互的基本单位是页，一个页的大小一般是 16 KB，一个页可能就存不了一条记录。这个时候就会发生行溢出，多的数据就会存到另外的溢出页中。

Compact 行格式：发生行溢出时，在记录的真实数据处只会保存该列的一部分数据，而把剩余的数据放在溢出页中，然后真实数据处用 20 字节存储指向溢出页的地址，从而可以找到剩余数据所在的页。

Compressed 和 Dynamic 这两种格式采用完全的行溢出方式，记录的真实数据处不会存储该列的一部分数据，只存储 20 个字节的指针来指向溢出页，实际的数据都存储在溢出页中。

### 页分裂

**使用非自增主键**，由于每次插入主键的索引值都是随机的，因此每次插入新的数据时，就可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面，这种情况称为页分裂。

- 页分裂会做数据的移动，极大地损耗写入性能。

- 页分裂会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率。

一个页快满了插入数据时，如果下一个页的空间也全部占满，MySQL 将创建一个新页，将快满的这个页的部分数据（超出页阈值）迁移到新页中，之后再插入新的数据。

![image-20240720235314037](https://gitee.com/fushengshi/image/raw/master/image-20240720235314037.png)





## B+ 树存储数据量

> 在《阿里开发手册》中建议，单表行数超过 500 万行或者单表容量超过 2 GB，才推荐进行分库分表，如果预计三年后数据量根本达不到这个级别，就不必要在创建表时就分库分表。

- InnoDB 存储引擎的最小存储单元是页，大小默认是 16K。

  页可用于存放 B+ 树叶节点数据，也可用于存放 B+ 树非叶节点的 [主键 + 指针]。

- 指针可以设置为占用 6 Byte。
- 假设主键类型为 bigint，3 层 B+ 树 可以存 2000w 数据。

计算过程：

- 非叶子节点

  假设主键类型为 bigint，占用 8 Byte，指针可以设置为占用 6 Byte，总共 14 Byte。

  一个非叶子节点大概可以存放 `16 * 1024 / 14 = 1170` 主键 + 指针的组合。

- 叶子节点

  假设我们的一行数据大小是1K Byte。

  一个叶子节点就可以存 `16k / 10k =16` 条（行）数据。

- 主键为 bigint 存储数据量：

  2 层 B+ 树：可以存放 `1170 * 16 = 18720` （行）数据。
  3 层 B+ 树：可以存放 `1170 * 1170 * 16 = 21902400` （行）数据。



## InnoDB 行格式

行格式（row_format），就是一条记录的存储结构。

Compact 行格式：

![image-20240514000342226](https://gitee.com/fushengshi/image/raw/master/image-20240514000342226.png)

### 变长字段长度列表

存储数据的时候，要把数据占用的大小存起来，存到变长字段长度列表里面，读取数据的时候根据这个变长字段长度列表去读取对应长度的数据。

变长字段长度列表只出现在数据表有变长字段的时候。

> 变长字段长度列表中的信息逆序存放，可以使得位置靠前的记录的真实数据和数据对应的字段长度信息可以同时在一个 CPU Cache Line 中，这样就可以提高 CPU Cache 的命中率。

###  NULL 值列表

表中的某些列可能会存储 NULL 值，如果把这些 NULL 值都放到记录的真实数据中会比较浪费空间，所以 Compact 行格式把这些值为 NULL 的列存储到 NULL 值列表中。

当数据表的字段都定义成 NOT NULL 的时候，这时候表里的行格式就不会有 NULL 值列表了。

所以在设计数据库表的时候，通常都是建议将字段设置为 NOT NULL，可以至少节省 1 字节的空间（NULL 值列表至少占用 1 字节空间）。

### 记录头信息

- next_record：下一条记录的位置。记录与记录之间是通过链表组织的，指向的是下一条记录的 记录头信息 和 真实数据 之间的位置，这样的好处是向左读就是记录头信息，向右读就是真实数据。

- delete_mask：标识此条数据是否被删除。执行 detele 删除记录的时候，并不会真正的删除记录，只是将这个记录的 delete_mask 标记为 1。

- record_type：表示当前记录的类型，0 表示普通记录，1 表示 B+ 树非叶子节点记录，2 表示最小记录，3 表示最大记录。

### 隐藏字段

- DB_TRX_ID（6 字节）：

  如果我们建表的时候指定了主键或者唯一约束列，那么就没有 row_id 隐藏字段了。如果既没有指定主键，又没有唯一约束，那么 InnoDB 就会为记录添加 row_id 隐藏字段。

- DB_ROW_ID（6 字节）：

  事务id，表示这个数据是由哪个事务生成的。

  当一个事务对某条聚簇索引记录进行改动时，就会把该事务的事务 id 记录在 trx_id 隐藏列里。

- DB_ROLL_PTR（7 字节）：

  这条记录上一个版本的指针。每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo log 中，隐藏列是个指针，指向每一个旧版本记录，可以通过它找到修改前的记录。



## 执行计划

对于执行计划，参数有：

- possible_keys 字段表示可能用到的索引。
- key 字段表示实际用的索引，如果这一项为 NULL，说明没有使用索引。
- key_len 表示索引的长度。
- rows 表示扫描的数据行数。
- type 表示数据扫描类型（重点）。

type 字段就是描述了找到所需数据时使用的扫描方式，常见扫描类型的**执行效率从低到高的顺序为**：

- All（全表扫描）
- index（全索引扫描）
- range（索引范围扫描）
- ref（非唯一索引扫描）
- eq_ref（唯一索引扫描）
- const（结果只有一条的主键或唯一索引扫描）



## 深度分页

查询偏移量过大的场景我们称为深度分页，这会导致查询性能较低：

```sql
SELECT * FROM t_order ORDER BY id LIMIT 1000000, 10
```

如何优化深度分页：

- 范围查询

  当可以保证 ID 的连续性时，根据 ID 范围进行分页。这种优化方式限制比较大，且一般项目的 ID 也没办法保证完全连续。

  ```sql
  SELECT * FROM t_order WHERE id > 100000 LIMIT 10
  ```

- 子查询

  先查询出 limit 第一个参数对应的主键值，再根据这个主键值再去过滤并 limit。

  子查询的结果会产生一张新表，会影响性能，应该尽量避免大量使用子查询。这种方法只适用于 ID 是正序的。在复杂分页场景，需要通过过滤条件筛选到符合条件的 ID，此时的 ID 是离散且不连续的。

  ```sql
  SELECT * FROM t_order WHERE id >= (SELECT id FROM t_order limit 1000000, 1) LIMIT 10;
  ```

- inner join延迟关联

  延迟关联的优化思路，跟子查询的优化思路其实是一样的，都是把条件转移到主键索引树，减少回表的次数。

  ```sql
  SELECT t1.* FROM t_order t1
  INNER JOIN (SELECT id FROM t_order limit 1000000, 10) t2
  ON t1.id = t2.id;
  ```

- 覆盖索引

  索引中已经包含了所有需要获取的字段的查询方式称为覆盖索引。避免 InnoDB 表进行索引的二次查询（回表），可以把随机 I/O 变成顺序 I/O 加快查询效率。

  ```sql
  SELECT id, code, type FROM t_order
  ORDER BY code
  LIMIT 1000000, 10;
  ```



## InnoDB 分区

分区的意思是指将同一表中不同行的记录分配到不同的物理文件中，几个分区就有几个 .idb 文件，不同于 InnoDB 逻辑存储结构中的段区页中的区。

- .frm 文件：表结构文件
- .ibd 文件：InnoDB 中，索引和数据都在同个文件。

分区是将一个表或索引分解成多个更小，更可管理的部分。每个区都是独立的，可以独立处理，也可以作为一个更大对象的一部分进行处理。这个是 MySQL 支持的功能，业务代码无需改动。分区一般都是放在单机里的，用的比较多的是时间范围分区，方便归档。如果表中存在主键或唯一索引时，分区列必须是唯一索引的一个组成部分。

> 分库分表需要代码实现，分区则是 MySQL 内部实现。分库分表和分区并不冲突，可以结合使用。

RANGE 分区是实战最常用的一种分区类型，行数据基于属于一个给定的连续区间的列值被放入分区。

```sql
create table table_name (
                          column0,
                          column1,
                          ...
)
  partition by range (用来分区的列名) (
    partition 分区0名称 values less than(对应条件值),
    partition 分区1名称 values less than(对应条件值),
    partition 分区2名称 values less than(对应条件值),
    ...
);
```



## 迁移数据库

### 双写方案

- 同步

  将新库配置为旧库的从库，同步数据。

  如果需要将数据同步到多库多表，可以使用第三方工具获取 binlog 的增量日志（比如 Canal），获取增量日志之后按照分库分表的逻辑写入到新的库表中。

- 双写

  改造业务代码，在数据写入时写入旧库和新库。

  可以异步地写入新库，保证旧库写入成功。需要将写入新库失败的数据记录在单独的日志中，方便后续数据补写，保证新库和旧库的数据一致性。

- 校验数据

- 切读

  当校验持续一段时间（如一周）时，如果数据一致性基本为 100% 时，可以启动切读。

  数据读取时对新库进行读取，通过灰度控制来进行小流量数据读取，观察一段时间没问题后逐步放大切读流量，直到 100% 读新库。

- 切写

  将数据库的双写改成只写新库。

### 级联同步方案

比较适合数据从自建机房向云上迁移的场景。迁移上云担心云上的环境和自建机房的环境不一致，会导致数据库在云上运行时，因为参数配置或者硬件环境不同出现问题。因此通过级联同步的方式在自建机房留下一个可回滚的数据库。

- 将新库（云）配置为旧库的从库，同步数据。

- 再将一个备库（自建机房）配置为新库的从库，用作数据的备份。

  备库作为在自建机房留下一个可回滚的数据库。

- 等到三个库的写入一致后，将数据库的读流量切换到新库。

- 暂停应用的写入，将业务的写入流量切换到新库。

> Redis 的数据迁移可以使用双写的方案或者级联同步的方案。
